{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hackathon_team2",
      "provenance": [],
      "collapsed_sections": [
        "1AosAX9DXOlc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJLee68/2020_cau_oss_hackathon/blob/master/hackathon_team2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1AosAX9DXOlc"
      },
      "source": [
        "# **0. 해커톤 진행 주의사항**\n",
        "\n",
        "**1)  개발 관련 주의사항**\n",
        "*   [1. 초기 환경 설정]은 절대 수정하지 말 것\n",
        "*   모든 구현은 [2. 데이터 전처리] 및 [3.모델 생성]에서만 진행\n",
        "*   [4. 모델 저장]에서 team_name 변수 변경 (예.`team_name = 'team01'`)\n",
        " *    트레이닝 중간에 checkpoint를 활용하여 모델을 저장한 경우에도 파일 이름 양식 통일 필수\n",
        "*   Colab 사용중 실수로 데이터 손실이 발생할 수도 있으니 중간 결과값을 github에 업로드 \n",
        " *    \"런타임->모든 런타임 재설정\"은 절대 누르지 말 것 (저장한 모델 데이터가 모두 삭제됨)\n",
        "*   효율적인 구현 및 테스팅을 위해 GPU 가속 기능 활성화\n",
        " *    \"런타임 -> 런타임 유형변경 -> 하드웨어 가속기 -> GPU 설정\"\n",
        "*   주석을 최대한 자세히 작성\n",
        "*   Keras API 관련하여 [Keras Documentation](https://keras.io/) 참조\n",
        "\n",
        "**2) 제출 관련 주의사항**\n",
        "*  제출물\n",
        " *  소스코드 (hackathon_teamXX.ipynb)\n",
        " *  컴파일된 모델 파일 (model_entire_teamXX.h5)\n",
        " *  모델 발표 자료 \n",
        "* 제출 기한: **오후 5시 (단, 발표자료는 11시)**\n",
        "* 제출 방법: [GitHub README](https://github.com/cauosshackathonta/2020_cau_oss_hackathon/) 참조\n",
        "\n",
        " \n",
        "**3) 평가 관련 주의사항**\n",
        "*  모델 성능 = 테스트 데이터 셋 분류 정확도\n",
        " *  model.evaluate(x_test, y_test)\n",
        "*  제출된 모델들의 테스트 데이터 셋 분류 정확도를 기준으로 수상작 결정\n",
        "*  수상 후보들에 대해서는 소스코드를 기반으로 모델 재검증 \n",
        " \n",
        "**4) 수상 실격 사유**\n",
        "*  유사한 소스코드 or 알고리즘이 적발될 경우\n",
        "*  소스코드와 제출된 모델이 상이한 경우\n",
        "*  개발 관련 주의사항을 지키지 않은 경우\n",
        " *  예: [초기 환경 설정]을 수정한 경우\n",
        "*  데이터 셋을 변조한 경우\n",
        " *  예. 테스트 데이터 셋을 트레이닝 데이터 셋에 포함하여 모델 생성 \n",
        "*  주석이 소스코드와 맞지 않거나 미비할 경우\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "67lwEXhUqys1"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ms5PBBJ1qSC6",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "check = !if [ -d 'dataset/' ]; then echo \"1\" ; else echo \"0\"; fi\n",
        "if (check[0] is '0' ):\n",
        "  !mkdir dataset\n",
        "  !wget 'https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip'\n",
        "  !unzip matlab.zip -d /content/dataset\n",
        "\n",
        "# 데이터셋 로드\n",
        "from scipy import io as spio\n",
        "emnist = spio.loadmat(\"/content/dataset/matlab/emnist-balanced.mat\")\n",
        "\n",
        "x_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
        "y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
        "\n",
        "x_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
        "y_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
        "\n",
        "# # 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 데이터 28x28 이미지화\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# 총 클래스 개수\n",
        "num_classes = y_test.shape[1]\n",
        "input_shape = x_test.shape[1:]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A-YjppJpXBO9"
      },
      "source": [
        "# **2. 데이터 전처리**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZ9KWTBP6AI1",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리 (예: normalization)\n",
        "x_train_after = x_train / 255.0\n",
        "x_test_after = x_test / 255.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGUMnrJDCG_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_num = y_train.shape[1]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v-lo-O1yiFpY"
      },
      "source": [
        "# **3. 모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niJteo94EXHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model, Model, Input, Sequential\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, MaxPool2D, ReLU, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from keras.backend import sigmoid\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCRV3MxBIQHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 아무래도 Imagenet data로 high accuracy가 입증이 된, VGG16, EfficientNet 등의 pretrained model을 가져와 학습하면 좋은 성능으로 이어지리라 생각을 했습니다.\n",
        "\n",
        "# 이번 해커톤의 데이터는 Imagenet data가 아니라, EMNIST 데이터이기에 모델 형식만 가져오고 scratch 부터 학습을 시켰습니다. \n",
        "# Scratch부터 훈련시킨 이유는 Imagenet data는 우선 크기도 훨씬 크고, RGB(3 channel)이고 image안에 여러 object가 있을 수 있는 반면,\n",
        "# Gray-scale(1 channel)이고 크기고 작고 object가 하나 밖에없는 EMNIST와는 달라서 다시 학습이 필요하다고 생각했기 때문입니다.\n",
        "# 그럼에도 불구하고 model의 형태 자체가 워낙 발전되고 입증된 모델이어서 좋은 성능을 기대헀는데, 제 기대와는 달리 accuracy가 높지 않았습니다.\n",
        "\n",
        "# Keras의 Imagedatagenerator 클래스를 통해 augmentation도 해봤는데(EMNIST 데이터를 직접 확인하니까, 약간 기울어져있는 것도 있었고 flip된 이미지도 보였습니다) 별 도움이 안되었고,\n",
        "# Scaling된 데이터들도 보이길래 FFT(Scale invariance를 가진)를 적용시켜서 훈련시켜볼 까 생각도 했지만, 득보단 실이 클것 같아서 하지 않았습니다.\n",
        "\n",
        "# 결국 그냥 단순하게 vgg 형식의 conv block(conv-batchnorm-activation)을 쌓는 것으로 방향을 바꿨는데 오히려 이게 더 성능이 좋아서, 이것으로 제출합니다.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48TYBlR9Ej0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "335cc881-ee58-48a2-e202-e98435f5c3a2"
      },
      "source": [
        "model =  keras.Sequential([\n",
        "    Conv2D(64, kernel_size = 3, strides = 1, padding='same', input_shape=(28,28,1)),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    Conv2D(64, kernel_size = 3, strides=1, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    MaxPool2D(pool_size=(2,2), strides=2),\n",
        "\n",
        "    Conv2D(128, kernel_size = 3, strides = 1, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    Conv2D(128, kernel_size = 3, strides=1, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    Conv2D(128, kernel_size = 3, strides=1, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    MaxPool2D(pool_size=(2,2), strides=2),\n",
        "\n",
        "    Conv2D(256, kernel_size = 3, strides = 1, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    Conv2D(256, kernel_size = 3, strides=1, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    Conv2D(256, kernel_size = 3, strides=1, padding='same'),\n",
        "    BatchNormalization(),\n",
        "    ReLU(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=2),\n",
        "    Flatten(),\n",
        "    Dense(1024, activation = 'relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(512, activation = 'relu'),\n",
        "    Dense(47, activation = 'softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "# optimizer: 모델을 업데이트 하는 방식\n",
        "# loss: 모델의 정확도를 판단하는 방식\n",
        "# metrics: 트레이닝 및 테스팅 성능 모니터링을 위한 평가지표\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_36 (ReLU)              (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_37 (ReLU)              (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_38 (ReLU)              (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_39 (ReLU)              (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_40 (ReLU)              (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "re_lu_41 (ReLU)              (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "re_lu_42 (ReLU)              (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "re_lu_43 (ReLU)              (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              2360320   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 47)                24111     \n",
            "=================================================================\n",
            "Total params: 4,796,271\n",
            "Trainable params: 4,793,711\n",
            "Non-trainable params: 2,560\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BodImlfYKRuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbf61165-da00-4c31-c05b-8fb1477e8304"
      },
      "source": [
        "# 체크포인트 생성\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='/content/checkpoint_entire_best.h5', monitor='val_accuracy', verbose=1, save_weight_only=False, save_best_only=True, mode='auto')\n",
        "\n",
        "# 모델 트레이닝\n",
        "# batch_size: 전체 데이터셋 중 몇개씩 학습시킬 것인지\n",
        "# epoch: 학습에 전체 데이터셋이 총 몇번 이용될 것인지\n",
        "# shuffle: 학습전에 트레이닝 데이터셋을 랜덤하게 섞을 것인지\n",
        "# validation_data: 중간 성능 검증에 사용할 data set\n",
        "model.fit(x_train_after, y_train, batch_size = 128, epochs = 50, shuffle=True, callbacks=[cp_callback], validation_data=(x_test_after, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "882/882 [==============================] - ETA: 0s - loss: 0.9657 - accuracy: 0.7136\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83904, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 34s 39ms/step - loss: 0.9657 - accuracy: 0.7136 - val_loss: 0.4677 - val_accuracy: 0.8390\n",
            "Epoch 2/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.8622\n",
            "Epoch 00002: val_accuracy improved from 0.83904 to 0.84840, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.3845 - accuracy: 0.8622 - val_loss: 0.4231 - val_accuracy: 0.8484\n",
            "Epoch 3/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.3421 - accuracy: 0.8756\n",
            "Epoch 00003: val_accuracy improved from 0.84840 to 0.86245, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.3422 - accuracy: 0.8756 - val_loss: 0.3947 - val_accuracy: 0.8624\n",
            "Epoch 4/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.3156 - accuracy: 0.8839\n",
            "Epoch 00004: val_accuracy improved from 0.86245 to 0.87718, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.3155 - accuracy: 0.8839 - val_loss: 0.3336 - val_accuracy: 0.8772\n",
            "Epoch 5/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8885\n",
            "Epoch 00005: val_accuracy improved from 0.87718 to 0.89021, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.3003 - accuracy: 0.8885 - val_loss: 0.3071 - val_accuracy: 0.8902\n",
            "Epoch 6/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2869 - accuracy: 0.8922\n",
            "Epoch 00006: val_accuracy did not improve from 0.89021\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.2868 - accuracy: 0.8923 - val_loss: 0.3254 - val_accuracy: 0.8862\n",
            "Epoch 7/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.8981\n",
            "Epoch 00007: val_accuracy improved from 0.89021 to 0.89282, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.2721 - accuracy: 0.8981 - val_loss: 0.3109 - val_accuracy: 0.8928\n",
            "Epoch 8/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.9010\n",
            "Epoch 00008: val_accuracy did not improve from 0.89282\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.2616 - accuracy: 0.9010 - val_loss: 0.3103 - val_accuracy: 0.8887\n",
            "Epoch 9/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2506 - accuracy: 0.9038\n",
            "Epoch 00009: val_accuracy did not improve from 0.89282\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.2506 - accuracy: 0.9038 - val_loss: 0.3168 - val_accuracy: 0.8919\n",
            "Epoch 10/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9068\n",
            "Epoch 00010: val_accuracy improved from 0.89282 to 0.89495, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.2415 - accuracy: 0.9069 - val_loss: 0.3043 - val_accuracy: 0.8949\n",
            "Epoch 11/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.9099\n",
            "Epoch 00011: val_accuracy did not improve from 0.89495\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.2321 - accuracy: 0.9098 - val_loss: 0.3141 - val_accuracy: 0.8888\n",
            "Epoch 12/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.9128\n",
            "Epoch 00012: val_accuracy did not improve from 0.89495\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.2234 - accuracy: 0.9128 - val_loss: 0.3265 - val_accuracy: 0.8864\n",
            "Epoch 13/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9160\n",
            "Epoch 00013: val_accuracy did not improve from 0.89495\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.2150 - accuracy: 0.9160 - val_loss: 0.3121 - val_accuracy: 0.8932\n",
            "Epoch 14/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.9179\n",
            "Epoch 00014: val_accuracy improved from 0.89495 to 0.89872, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.2066 - accuracy: 0.9179 - val_loss: 0.3054 - val_accuracy: 0.8987\n",
            "Epoch 15/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9210\n",
            "Epoch 00015: val_accuracy improved from 0.89872 to 0.90053, saving model to /content/checkpoint_entire_best.h5\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.1993 - accuracy: 0.9210 - val_loss: 0.2989 - val_accuracy: 0.9005\n",
            "Epoch 16/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1910 - accuracy: 0.9235\n",
            "Epoch 00016: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.1910 - accuracy: 0.9235 - val_loss: 0.3361 - val_accuracy: 0.8920\n",
            "Epoch 17/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1827 - accuracy: 0.9265\n",
            "Epoch 00017: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.1827 - accuracy: 0.9265 - val_loss: 0.3167 - val_accuracy: 0.8995\n",
            "Epoch 18/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9288\n",
            "Epoch 00018: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.1747 - accuracy: 0.9288 - val_loss: 0.3185 - val_accuracy: 0.8989\n",
            "Epoch 19/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1683 - accuracy: 0.9318\n",
            "Epoch 00019: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.1683 - accuracy: 0.9318 - val_loss: 0.3386 - val_accuracy: 0.8952\n",
            "Epoch 20/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9339\n",
            "Epoch 00020: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.1607 - accuracy: 0.9340 - val_loss: 0.3398 - val_accuracy: 0.8955\n",
            "Epoch 21/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9370\n",
            "Epoch 00021: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.1549 - accuracy: 0.9370 - val_loss: 0.3437 - val_accuracy: 0.8965\n",
            "Epoch 22/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.9395\n",
            "Epoch 00022: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.1472 - accuracy: 0.9395 - val_loss: 0.3785 - val_accuracy: 0.8955\n",
            "Epoch 23/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9426\n",
            "Epoch 00023: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.1391 - accuracy: 0.9426 - val_loss: 0.3775 - val_accuracy: 0.8952\n",
            "Epoch 24/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9449\n",
            "Epoch 00024: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.1338 - accuracy: 0.9449 - val_loss: 0.3869 - val_accuracy: 0.8964\n",
            "Epoch 25/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1249 - accuracy: 0.9483\n",
            "Epoch 00025: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.1249 - accuracy: 0.9483 - val_loss: 0.4086 - val_accuracy: 0.8946\n",
            "Epoch 26/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9510\n",
            "Epoch 00026: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.1194 - accuracy: 0.9510 - val_loss: 0.4171 - val_accuracy: 0.8941\n",
            "Epoch 27/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9548\n",
            "Epoch 00027: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.1101 - accuracy: 0.9548 - val_loss: 0.4154 - val_accuracy: 0.8930\n",
            "Epoch 28/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 0.9581\n",
            "Epoch 00028: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.1037 - accuracy: 0.9580 - val_loss: 0.4359 - val_accuracy: 0.8901\n",
            "Epoch 29/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9606\n",
            "Epoch 00029: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0973 - accuracy: 0.9606 - val_loss: 0.4688 - val_accuracy: 0.8894\n",
            "Epoch 30/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0902 - accuracy: 0.9641\n",
            "Epoch 00030: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0901 - accuracy: 0.9641 - val_loss: 0.5101 - val_accuracy: 0.8862\n",
            "Epoch 31/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9673\n",
            "Epoch 00031: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0830 - accuracy: 0.9673 - val_loss: 0.4798 - val_accuracy: 0.8906\n",
            "Epoch 32/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9692\n",
            "Epoch 00032: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0770 - accuracy: 0.9693 - val_loss: 0.5505 - val_accuracy: 0.8878\n",
            "Epoch 33/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9721\n",
            "Epoch 00033: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0719 - accuracy: 0.9722 - val_loss: 0.5882 - val_accuracy: 0.8887\n",
            "Epoch 34/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9751\n",
            "Epoch 00034: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0643 - accuracy: 0.9752 - val_loss: 0.5880 - val_accuracy: 0.8921\n",
            "Epoch 35/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9760\n",
            "Epoch 00035: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0640 - accuracy: 0.9760 - val_loss: 0.5913 - val_accuracy: 0.8859\n",
            "Epoch 36/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9787\n",
            "Epoch 00036: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0580 - accuracy: 0.9787 - val_loss: 0.6023 - val_accuracy: 0.8831\n",
            "Epoch 37/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9799\n",
            "Epoch 00037: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.0533 - accuracy: 0.9799 - val_loss: 0.6288 - val_accuracy: 0.8852\n",
            "Epoch 38/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9820\n",
            "Epoch 00038: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0497 - accuracy: 0.9820 - val_loss: 0.6674 - val_accuracy: 0.8869\n",
            "Epoch 39/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9836\n",
            "Epoch 00039: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.6698 - val_accuracy: 0.8892\n",
            "Epoch 40/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9845\n",
            "Epoch 00040: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0436 - accuracy: 0.9845 - val_loss: 0.6917 - val_accuracy: 0.8847\n",
            "Epoch 41/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9849\n",
            "Epoch 00041: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0428 - accuracy: 0.9849 - val_loss: 0.7122 - val_accuracy: 0.8844\n",
            "Epoch 42/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0386 - accuracy: 0.9867\n",
            "Epoch 00042: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0387 - accuracy: 0.9867 - val_loss: 0.7340 - val_accuracy: 0.8871\n",
            "Epoch 43/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9867\n",
            "Epoch 00043: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.7241 - val_accuracy: 0.8857\n",
            "Epoch 44/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9886\n",
            "Epoch 00044: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.8092 - val_accuracy: 0.8851\n",
            "Epoch 45/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9886\n",
            "Epoch 00045: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 0.7280 - val_accuracy: 0.8889\n",
            "Epoch 46/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9882\n",
            "Epoch 00046: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.7797 - val_accuracy: 0.8849\n",
            "Epoch 47/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9885\n",
            "Epoch 00047: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.7751 - val_accuracy: 0.8840\n",
            "Epoch 48/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9902\n",
            "Epoch 00048: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 38ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.8474 - val_accuracy: 0.8894\n",
            "Epoch 49/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9906\n",
            "Epoch 00049: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.8478 - val_accuracy: 0.8888\n",
            "Epoch 50/50\n",
            "881/882 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9904\n",
            "Epoch 00050: val_accuracy did not improve from 0.90053\n",
            "882/882 [==============================] - 33s 37ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.7968 - val_accuracy: 0.8866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c542cb5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QR9WUYXxqtfR"
      },
      "source": [
        "# **4. 모델 저장**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wi9yznz4qvzK",
        "colab": {}
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team2'\n",
        "\n",
        "# 트레이닝된 전체 모델을 저장합니다.\n",
        "model.save(save_path +  'model_entire_'+ team_name + '.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4aPbgI-c-Kj8"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y7WONVxH-Kt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d713f803-38c8-42d7-f746-5a819201779a"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team2'\n",
        "\n",
        "model = keras.models.load_model(save_path + 'model_entire_' + team_name + '.h5')\n",
        "\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 3s 5ms/step - loss: 0.7968 - accuracy: 0.8866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7967966198921204, 0.8865957260131836]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAQciumTzVlh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ac3cfb64-ddf3-488a-9fe8-11598d15b90c"
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team2'\n",
        "\n",
        "model = keras.models.load_model(save_path + 'checkpoint_entire_best' + '.h5')\n",
        "\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 3s 5ms/step - loss: 0.2989 - accuracy: 0.9005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2988581657409668, 0.9005318880081177]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJDn4hxFOFjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}